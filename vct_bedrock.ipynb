{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37cb48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ea81616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opensearch-py==2.3.1\n",
      "  Downloading opensearch_py-2.3.1-py2.py3-none-any.whl (327 kB)\n",
      "Requirement already satisfied: urllib3<2,>=1.21.1 in c:\\users\\deepm\\anaconda3\\lib\\site-packages (from opensearch-py==2.3.1) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\deepm\\anaconda3\\lib\\site-packages (from opensearch-py==2.3.1) (2.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.4.0 in c:\\users\\deepm\\anaconda3\\lib\\site-packages (from opensearch-py==2.3.1) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\deepm\\anaconda3\\lib\\site-packages (from opensearch-py==2.3.1) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in c:\\users\\deepm\\anaconda3\\lib\\site-packages (from opensearch-py==2.3.1) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\deepm\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.4.0->opensearch-py==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deepm\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.4.0->opensearch-py==2.3.1) (3.2)\n",
      "Installing collected packages: opensearch-py\n",
      "Successfully installed opensearch-py-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting retrying==1.3.4\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\users\\deepm\\anaconda3\\lib\\site-packages (from retrying==1.3.4) (1.16.0)\n",
      "Installing collected packages: retrying\n",
      "Successfully installed retrying-1.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install -U opensearch-py==2.3.1\n",
    "# %pip install -U boto3==1.33.2\n",
    "%pip install -U retrying==1.3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03377e",
   "metadata": {},
   "source": [
    "# AWS Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f9ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set AWS credentials as environment variables\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'AKIAS2VS4CX5YKN7URUZ'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'SAQ79USa3dOU5qoeVAZam0aAFPcgwA6Hz7DCi5BQ'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'  # Change to your preferred region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9333d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "suffix = random.randrange(200, 900)\n",
    "boto3_session = boto3.session.Session()\n",
    "region_name = boto3_session.region_name\n",
    "iam_client = boto3_session.client('iam')\n",
    "account_number = boto3.client('sts').get_caller_identity().get('Account')\n",
    "identity = boto3.client('sts').get_caller_identity()['Arn']\n",
    "\n",
    "encryption_policy_name = f\"bedrock-sample-rag-sp-{suffix}\"\n",
    "network_policy_name = f\"bedrock-sample-rag-np-{suffix}\"\n",
    "access_policy_name = f'bedrock-sample-rag-ap-{suffix}'\n",
    "bedrock_execution_role_name = f'AmazonBedrockExecutionRoleForKnowledgeBase_{suffix}'\n",
    "fm_policy_name = f'AmazonBedrockFoundationModelPolicyForKnowledgeBase_{suffix}'\n",
    "s3_policy_name = f'AmazonBedrockS3PolicyForKnowledgeBase_{suffix}'\n",
    "oss_policy_name = f'AmazonBedrockOSSPolicyForKnowledgeBase_{suffix}'\n",
    "\n",
    "\n",
    "def create_bedrock_execution_role(bucket_name):\n",
    "    foundation_model_policy_document = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"bedrock:InvokeModel\",\n",
    "                ],\n",
    "                \"Resource\": [\n",
    "                    f\"arn:aws:bedrock:{region_name}::foundation-model/amazon.titan-embed-text-v1\"\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    s3_policy_document = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"s3:GetObject\",\n",
    "                    \"s3:ListBucket\"\n",
    "                ],\n",
    "                \"Resource\": [\n",
    "                    f\"arn:aws:s3:::{bucket_name}\",\n",
    "                    f\"arn:aws:s3:::{bucket_name}/*\"\n",
    "                ],\n",
    "                \"Condition\": {\n",
    "                    \"StringEquals\": {\n",
    "                        \"aws:ResourceAccount\": f\"{account_number}\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    assume_role_policy_document = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"Service\": \"bedrock.amazonaws.com\"\n",
    "                },\n",
    "                \"Action\": \"sts:AssumeRole\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    # create policies based on the policy documents\n",
    "    fm_policy = iam_client.create_policy(\n",
    "        PolicyName=fm_policy_name,\n",
    "        PolicyDocument=json.dumps(foundation_model_policy_document),\n",
    "        Description='Policy for accessing foundation model',\n",
    "    )\n",
    "\n",
    "    s3_policy = iam_client.create_policy(\n",
    "        PolicyName=s3_policy_name,\n",
    "        PolicyDocument=json.dumps(s3_policy_document),\n",
    "        Description='Policy for reading documents from s3')\n",
    "\n",
    "    # create bedrock execution role\n",
    "    bedrock_kb_execution_role = iam_client.create_role(\n",
    "        RoleName=bedrock_execution_role_name,\n",
    "        AssumeRolePolicyDocument=json.dumps(assume_role_policy_document),\n",
    "        Description='Amazon Bedrock Knowledge Base Execution Role for accessing OSS and S3',\n",
    "        MaxSessionDuration=3600\n",
    "    )\n",
    "\n",
    "    # fetch arn of the policies and role created above\n",
    "    bedrock_kb_execution_role_arn = bedrock_kb_execution_role['Role']['Arn']\n",
    "    s3_policy_arn = s3_policy[\"Policy\"][\"Arn\"]\n",
    "    fm_policy_arn = fm_policy[\"Policy\"][\"Arn\"]\n",
    "\n",
    "    # attach policies to Amazon Bedrock execution role\n",
    "    iam_client.attach_role_policy(\n",
    "        RoleName=bedrock_kb_execution_role[\"Role\"][\"RoleName\"],\n",
    "        PolicyArn=fm_policy_arn\n",
    "    )\n",
    "    iam_client.attach_role_policy(\n",
    "        RoleName=bedrock_kb_execution_role[\"Role\"][\"RoleName\"],\n",
    "        PolicyArn=s3_policy_arn\n",
    "    )\n",
    "    return bedrock_kb_execution_role\n",
    "\n",
    "\n",
    "def create_oss_policy_attach_bedrock_execution_role(collection_id, bedrock_kb_execution_role):\n",
    "    # define oss policy document\n",
    "    oss_policy_document = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"aoss:APIAccessAll\"\n",
    "                ],\n",
    "                \"Resource\": [\n",
    "                    f\"arn:aws:aoss:{region_name}:{account_number}:collection/{collection_id}\"\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    oss_policy = iam_client.create_policy(\n",
    "        PolicyName=oss_policy_name,\n",
    "        PolicyDocument=json.dumps(oss_policy_document),\n",
    "        Description='Policy for accessing opensearch serverless',\n",
    "    )\n",
    "    oss_policy_arn = oss_policy[\"Policy\"][\"Arn\"]\n",
    "    print(\"Opensearch serverless arn: \", oss_policy_arn)\n",
    "\n",
    "    iam_client.attach_role_policy(\n",
    "        RoleName=bedrock_kb_execution_role[\"Role\"][\"RoleName\"],\n",
    "        PolicyArn=oss_policy_arn\n",
    "    )\n",
    "    return None\n",
    "\n",
    "\n",
    "def create_policies_in_oss(vector_store_name, aoss_client, bedrock_kb_execution_role_arn):\n",
    "    encryption_policy = aoss_client.create_security_policy(\n",
    "        name=encryption_policy_name,\n",
    "        policy=json.dumps(\n",
    "            {\n",
    "                'Rules': [{'Resource': ['collection/' + vector_store_name],\n",
    "                           'ResourceType': 'collection'}],\n",
    "                'AWSOwnedKey': True\n",
    "            }),\n",
    "        type='encryption'\n",
    "    )\n",
    "\n",
    "    network_policy = aoss_client.create_security_policy(\n",
    "        name=network_policy_name,\n",
    "        policy=json.dumps(\n",
    "            [\n",
    "                {'Rules': [{'Resource': ['collection/' + vector_store_name],\n",
    "                            'ResourceType': 'collection'}],\n",
    "                 'AllowFromPublic': True}\n",
    "            ]),\n",
    "        type='network'\n",
    "    )\n",
    "    access_policy = aoss_client.create_access_policy(\n",
    "        name=access_policy_name,\n",
    "        policy=json.dumps(\n",
    "            [\n",
    "                {\n",
    "                    'Rules': [\n",
    "                        {\n",
    "                            'Resource': ['collection/' + vector_store_name],\n",
    "                            'Permission': [\n",
    "                                'aoss:CreateCollectionItems',\n",
    "                                'aoss:DeleteCollectionItems',\n",
    "                                'aoss:UpdateCollectionItems',\n",
    "                                'aoss:DescribeCollectionItems'],\n",
    "                            'ResourceType': 'collection'\n",
    "                        },\n",
    "                        {\n",
    "                            'Resource': ['index/' + vector_store_name + '/*'],\n",
    "                            'Permission': [\n",
    "                                'aoss:CreateIndex',\n",
    "                                'aoss:DeleteIndex',\n",
    "                                'aoss:UpdateIndex',\n",
    "                                'aoss:DescribeIndex',\n",
    "                                'aoss:ReadDocument',\n",
    "                                'aoss:WriteDocument'],\n",
    "                            'ResourceType': 'index'\n",
    "                        }],\n",
    "                    'Principal': [identity, bedrock_kb_execution_role_arn],\n",
    "                    'Description': 'Easy data policy'}\n",
    "            ]),\n",
    "        type='data'\n",
    "    )\n",
    "    return encryption_policy, network_policy, access_policy\n",
    "\n",
    "\n",
    "def delete_iam_role_and_policies():\n",
    "    fm_policy_arn = f\"arn:aws:iam::{account_number}:policy/{fm_policy_name}\"\n",
    "    s3_policy_arn = f\"arn:aws:iam::{account_number}:policy/{s3_policy_name}\"\n",
    "    oss_policy_arn = f\"arn:aws:iam::{account_number}:policy/{oss_policy_name}\"\n",
    "    iam_client.detach_role_policy(\n",
    "        RoleName=bedrock_execution_role_name,\n",
    "        PolicyArn=s3_policy_arn\n",
    "    )\n",
    "    iam_client.detach_role_policy(\n",
    "        RoleName=bedrock_execution_role_name,\n",
    "        PolicyArn=fm_policy_arn\n",
    "    )\n",
    "    iam_client.detach_role_policy(\n",
    "        RoleName=bedrock_execution_role_name,\n",
    "        PolicyArn=oss_policy_arn\n",
    "    )\n",
    "    iam_client.delete_role(RoleName=bedrock_execution_role_name)\n",
    "    iam_client.delete_policy(PolicyArn=s3_policy_arn)\n",
    "    iam_client.delete_policy(PolicyArn=fm_policy_arn)\n",
    "    iam_client.delete_policy(PolicyArn=oss_policy_arn)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def interactive_sleep(seconds: int):\n",
    "    dots = ''\n",
    "    for i in range(seconds):\n",
    "        dots += '.'\n",
    "        print(dots, end='\\r')\n",
    "        time.sleep(1)\n",
    "    # print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fd74f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import pprint\n",
    "from utility import create_bedrock_execution_role, create_oss_policy_attach_bedrock_execution_role, create_policies_in_oss, interactive_sleep\n",
    "import random\n",
    "from retrying import retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c794774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = 'VCT_SAKEC'\n",
    "\n",
    "sts_client = boto3.client('sts')\n",
    "boto3_session = boto3.session.Session()\n",
    "region_name = boto3_session.region_name\n",
    "bedrock_agent_client = boto3_session.client('bedrock-agent', region_name=region_name)\n",
    "service = 'aoss'\n",
    "s3_client = boto3.client('s3')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "s3_suffix = f\"{region_name}-{account_id}\"\n",
    "bucket_name = f'vlrscraperbucket' # replace it with your bucket name.\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1d5984",
   "metadata": {},
   "source": [
    "# Check if bucket exists, and if not create S3 bucket for knowledge base data source\n",
    "try:\n",
    "    s3_client.head_bucket(Bucket=bucket_name)\n",
    "    print(f'Bucket {bucket_name} Exists')\n",
    "except ClientError as e:\n",
    "    print(f'Creating bucket {bucket_name}')\n",
    "    if region_name == \"us-east-1\":\n",
    "        s3bucket = s3_client.create_bucket(\n",
    "            Bucket=bucket_name)\n",
    "    else:\n",
    "        s3bucket = s3_client.create_bucket(\n",
    "        Bucket=bucket_name,\n",
    "        CreateBucketConfiguration={ 'LocationConstraint': region_name }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb4768f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket vlrscraperbucket Exists\n",
      "Files in the bucket:\n",
      "Metadata for JSON Structure.txt\n",
      "players_data (1).json\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "import random\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Create a session and S3 client\n",
    "boto3_session = boto3.session.Session()\n",
    "s3_client = boto3_session.client('s3')\n",
    "\n",
    "# Define the bucket name\n",
    "suffix = random.randrange(200, 900)\n",
    "region_name = boto3_session.region_name\n",
    "account_id = boto3.client('sts').get_caller_identity()[\"Account\"]\n",
    "s3_suffix = f\"us-east-1-{account_id}\"  # Corrected: 'us-east-1' should be in quotes\n",
    "bucket_name = f'vlrscraperbucket'  # Replace this with your bucket name.\n",
    "\n",
    "# Check if bucket exists, and if not create S3 bucket for knowledge base data source\n",
    "try:\n",
    "    s3_client.head_bucket(Bucket=bucket_name)\n",
    "    print(f'Bucket {bucket_name} Exists')\n",
    "except ClientError:\n",
    "    print(f'Creating bucket {bucket_name}')\n",
    "    if region_name == \"us-east-1\":\n",
    "        s3_client.create_bucket(Bucket=bucket_name)\n",
    "    else:\n",
    "        s3_client.create_bucket(\n",
    "            Bucket=bucket_name,\n",
    "            CreateBucketConfiguration={'LocationConstraint': region_name}\n",
    "        )\n",
    "\n",
    "# List files in the S3 bucket and store information\n",
    "file_info = []  # Initialize a list to store file information\n",
    "try:\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "    if 'Contents' in response:\n",
    "        print(\"Files in the bucket:\")\n",
    "        for obj in response['Contents']:\n",
    "            print(obj['Key'])  # Print the file path/key in the bucket\n",
    "            file_info.append(obj['Key'])  # Store file key in the list\n",
    "    else:\n",
    "        print(f\"No files found in bucket {bucket_name}.\")\n",
    "except ClientError as e:\n",
    "    print(f\"Error listing files: {str(e)}\")\n",
    "\n",
    "# Store the file information in the variable\n",
    "bucket_file_info = file_info  # You can use this variable as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a6706e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'bucket_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "530d1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "vector_store_name = f'bedrock-sample-rag-{suffix}'\n",
    "index_name = f\"bedrock-sample-rag-index-{suffix}\"\n",
    "aoss_client = boto3_session.client('opensearchserverless')\n",
    "bedrock_kb_execution_role = create_bedrock_execution_role(bucket_name=bucket_name)\n",
    "bedrock_kb_execution_role_arn = bedrock_kb_execution_role['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1134709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create security, network and data access policies within OSS\n",
    "encryption_policy, network_policy, access_policy = create_policies_in_oss(vector_store_name=vector_store_name,\n",
    "                       aoss_client=aoss_client,\n",
    "                       bedrock_kb_execution_role_arn=bedrock_kb_execution_role_arn)\n",
    "collection = aoss_client.create_collection(name=vector_store_name,type='VECTORSEARCH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85a9cf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'ResponseMetadata': { 'HTTPHeaders': { 'connection': 'keep-alive',\n",
      "                                         'content-length': '314',\n",
      "                                         'content-type': 'application/x-amz-json-1.0',\n",
      "                                         'date': 'Tue, 08 Oct 2024 21:45:58 '\n",
      "                                                 'GMT',\n",
      "                                         'x-amzn-requestid': '6357f3fe-f058-4d9a-94fd-303374eaecc9'},\n",
      "                        'HTTPStatusCode': 200,\n",
      "                        'RequestId': '6357f3fe-f058-4d9a-94fd-303374eaecc9',\n",
      "                        'RetryAttempts': 0},\n",
      "  'createCollectionDetail': { 'arn': 'arn:aws:aoss:us-east-1:194722403835:collection/sih12shy7voec25uj5gc',\n",
      "                              'createdDate': 1728423958484,\n",
      "                              'id': 'sih12shy7voec25uj5gc',\n",
      "                              'kmsKeyArn': 'auto',\n",
      "                              'lastModifiedDate': 1728423958484,\n",
      "                              'name': 'bedrock-sample-rag-595',\n",
      "                              'standbyReplicas': 'ENABLED',\n",
      "                              'status': 'CREATING',\n",
      "                              'type': 'VECTORSEARCH'}}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5befa980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'encryption_policy' (dict)\n",
      "Stored 'network_policy' (dict)\n",
      "Stored 'access_policy' (dict)\n",
      "Stored 'collection' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store encryption_policy network_policy access_policy collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25ef8baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sih12shy7voec25uj5gc.us-east-1.aoss.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "# Get the OpenSearch serverless collection URL\n",
    "collection_id = collection['createCollectionDetail']['id']\n",
    "host = collection_id + '.' + region_name + '.aoss.amazonaws.com'\n",
    "print(host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad0dcc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating collection...\n",
      "Creating collection...........\n",
      "..............................\n",
      "Collection successfully created:\n",
      "[ { 'arn': 'arn:aws:aoss:us-east-1:194722403835:collection/01edekk2r8679tabbl17',\n",
      "    'collectionEndpoint': 'https://01edekk2r8679tabbl17.us-east-1.aoss.amazonaws.com',\n",
      "    'createdDate': 1728138137748,\n",
      "    'dashboardEndpoint': 'https://01edekk2r8679tabbl17.us-east-1.aoss.amazonaws.com/_dashboards',\n",
      "    'id': '01edekk2r8679tabbl17',\n",
      "    'kmsKeyArn': 'auto',\n",
      "    'lastModifiedDate': 1728138375158,\n",
      "    'name': 'bedrock-sample-rag-484',\n",
      "    'standbyReplicas': 'ENABLED',\n",
      "    'status': 'ACTIVE',\n",
      "    'type': 'VECTORSEARCH'}]\n"
     ]
    }
   ],
   "source": [
    "# wait for collection creation\n",
    "# This can take couple of minutes to finish\n",
    "response = aoss_client.batch_get_collection(names=[vector_store_name])\n",
    "# Periodically check collection status\n",
    "while (response['collectionDetails'][0]['status']) == 'CREATING':\n",
    "    print('Creating collection...')\n",
    "    interactive_sleep(30)\n",
    "    response = aoss_client.batch_get_collection(names=[vector_store_name])\n",
    "print('\\nCollection successfully created:')\n",
    "pp.pprint(response[\"collectionDetails\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "297c47eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opensearch serverless arn:  arn:aws:iam::194722403835:policy/AmazonBedrockOSSPolicyForKnowledgeBase_583\n",
      "............................................................\r"
     ]
    }
   ],
   "source": [
    "# create opensearch serverless access policy and attach it to Bedrock execution role\n",
    "try:\n",
    "    create_oss_policy_attach_bedrock_execution_role(collection_id=collection_id,\n",
    "                                                    bedrock_kb_execution_role=bedrock_kb_execution_role)\n",
    "    # It can take up to a minute for data access rules to be enforced\n",
    "    interactive_sleep(60)\n",
    "except Exception as e:\n",
    "    print(\"Policy already exists\")\n",
    "    pp.pprint(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba41b55d",
   "metadata": {},
   "source": [
    "# Step 2 - Create vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccce5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vector index in Opensearch serverless, with the knn_vector field index mapping, specifying the dimension size, name and engine.\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth, RequestError\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = auth = AWSV4SignerAuth(credentials, region_name, service)\n",
    "\n",
    "index_name = f\"bedrock-sample-index-{suffix}\"\n",
    "body_json = {\n",
    "   \"settings\": {\n",
    "      \"index.knn\": \"true\",\n",
    "       \"number_of_shards\": 1,\n",
    "       \"knn.algo_param.ef_search\": 512,\n",
    "       \"number_of_replicas\": 0,\n",
    "   },\n",
    "   \"mappings\": {\n",
    "      \"properties\": {\n",
    "         \"vector\": {\n",
    "            \"type\": \"knn_vector\",\n",
    "            \"dimension\": 1536,\n",
    "             \"method\": {\n",
    "                 \"name\": \"hnsw\",\n",
    "                 \"engine\": \"faiss\",\n",
    "                 \"space_type\": \"l2\"\n",
    "             },\n",
    "         },\n",
    "         \"text\": {\n",
    "            \"type\": \"text\"\n",
    "         },\n",
    "         \"text-metadata\": {\n",
    "            \"type\": \"text\"         }\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "# Build the OpenSearch client\n",
    "oss_client = OpenSearch(\n",
    "    hosts=[{'host': host, 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "386e1583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating index:\n",
      "{ 'acknowledged': True,\n",
      "  'index': 'bedrock-sample-index-595',\n",
      "  'shards_acknowledged': True}\n",
      "............................................................\r"
     ]
    }
   ],
   "source": [
    "# Create index\n",
    "try:\n",
    "    response = oss_client.indices.create(index=index_name, body=json.dumps(body_json))\n",
    "    print('\\nCreating index:')\n",
    "    pp.pprint(response)\n",
    "\n",
    "    # index creation can take up to a minute\n",
    "    interactive_sleep(60)\n",
    "except RequestError as e:\n",
    "    # you can delete the index if its already exists\n",
    "    # oss_client.indices.delete(index=index_name)\n",
    "    print(f'Error while trying to create the index, with error {e.error}\\nyou may unmark the delete above to delete, and recreate the index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98eedecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded AMZN-2022-Shareholder-Letter.pdf to ./data/AMZN-2022-Shareholder-Letter.pdf\n",
      "Downloaded AMZN-2021-Shareholder-Letter.pdf to ./data/AMZN-2021-Shareholder-Letter.pdf\n",
      "Downloaded AMZN-2020-Shareholder-Letter.pdf to ./data/AMZN-2020-Shareholder-Letter.pdf\n",
      "Downloaded AMZN-2019-Shareholder-Letter.pdf to ./data/AMZN-2019-Shareholder-Letter.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "data_root = \"./data/\"\n",
    "os.makedirs(data_root, exist_ok=True)\n",
    "\n",
    "# List of URLs and filenames\n",
    "urls = [\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Shareholder-Letter-and-1997-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "filenames = [\n",
    "    'AMZN-2022-Shareholder-Letter.pdf',\n",
    "    'AMZN-2021-Shareholder-Letter.pdf',\n",
    "    'AMZN-2020-Shareholder-Letter.pdf',\n",
    "    'AMZN-2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "# Download the files\n",
    "for idx, url in enumerate(urls):\n",
    "    file_path = data_root + filenames[idx]\n",
    "    urlretrieve(url, file_path)\n",
    "    print(f\"Downloaded {filenames[idx]} to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade417e2",
   "metadata": {},
   "source": [
    "# Upload data to S3 Bucket data source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "138c5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data to s3 to the bucket that was configured as a data source to the knowledge base\n",
    "s3_client = boto3.client(\"s3\")\n",
    "def uploadDirectory(path,bucket_name):\n",
    "        for root,dirs,files in os.walk(path):\n",
    "            for file in files:\n",
    "                s3_client.upload_file(os.path.join(root,file),bucket_name,file)\n",
    "\n",
    "uploadDirectory(data_root, bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e0299b",
   "metadata": {},
   "source": [
    "# Create Knowledge Base\n",
    "\n",
    "Steps:\n",
    "\n",
    "initialize Open search serverless configuration which will include collection ARN, index name, vector field, text field and metadata field.\n",
    "\n",
    "initialize chunking strategy, based on which KB will split the documents into pieces of size equal to the chunk size mentioned in the chunkingStrategyConfiguration.\n",
    "\n",
    "initialize the s3 configuration, which will be used to create the data source object later.\n",
    "\n",
    "initialize the Titan embeddings model ARN, as this will be used to create the embeddings for each of the text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "786435ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "opensearchServerlessConfiguration = {\n",
    "            \"collectionArn\": collection[\"createCollectionDetail\"]['arn'],\n",
    "            \"vectorIndexName\": index_name,\n",
    "            \"fieldMapping\": {\n",
    "                \"vectorField\": \"vector\",\n",
    "                \"textField\": \"text\",\n",
    "                \"metadataField\": \"text-metadata\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Ingest strategy - How to ingest data from the data source\n",
    "chunkingStrategyConfiguration = {\n",
    "    \"chunkingStrategy\": \"FIXED_SIZE\",\n",
    "    \"fixedSizeChunkingConfiguration\": {\n",
    "        \"maxTokens\": 512,\n",
    "        \"overlapPercentage\": 20\n",
    "    }\n",
    "}\n",
    "\n",
    "# The data source to ingest documents from, into the OpenSearch serverless knowledge base index\n",
    "s3Configuration = {\n",
    "    \"bucketArn\": f\"arn:aws:s3:::{bucket_name}\",\n",
    "    # \"inclusionPrefixes\":[\"*.*\"] # you can use this if you want to create a KB using data within s3 prefixes.\n",
    "}\n",
    "\n",
    "# The embedding model used by Bedrock to embed ingested documents, and realtime prompts\n",
    "embeddingModelArn = f\"arn:aws:bedrock:{region_name}::foundation-model/amazon.titan-embed-text-v1\"\n",
    "\n",
    "name = f\"bedrock-sample-knowledge-base-{suffix}\"\n",
    "description = \"Amazon shareholder letter knowledge base.\"\n",
    "roleArn = bedrock_kb_execution_role_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6e8463",
   "metadata": {},
   "source": [
    "Provide the above configurations as input to the create_knowledge_base method, which will create the Knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d5482b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KnowledgeBase\n",
    "from retrying import retry\n",
    "\n",
    "@retry(wait_random_min=1000, wait_random_max=2000,stop_max_attempt_number=7)\n",
    "def create_knowledge_base_func():\n",
    "    create_kb_response = bedrock_agent_client.create_knowledge_base(\n",
    "        name = name,\n",
    "        description = description,\n",
    "        roleArn = roleArn,\n",
    "        knowledgeBaseConfiguration = {\n",
    "            \"type\": \"VECTOR\",\n",
    "            \"vectorKnowledgeBaseConfiguration\": {\n",
    "                \"embeddingModelArn\": embeddingModelArn\n",
    "            }\n",
    "        },\n",
    "        storageConfiguration = {\n",
    "            \"type\": \"OPENSEARCH_SERVERLESS\",\n",
    "            \"opensearchServerlessConfiguration\":opensearchServerlessConfiguration\n",
    "        }\n",
    "    )\n",
    "    return create_kb_response[\"knowledgeBase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d086867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    kb = create_knowledge_base_func()\n",
    "except Exception as err:\n",
    "    print(f\"{err=}, {type(err)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78cb5bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'createdAt': datetime.datetime(2024, 10, 8, 21, 49, 40, 803792, tzinfo=tzutc()),\n",
      "  'description': 'Amazon shareholder letter knowledge base.',\n",
      "  'knowledgeBaseArn': 'arn:aws:bedrock:us-east-1:194722403835:knowledge-base/NE0M3BPNVV',\n",
      "  'knowledgeBaseConfiguration': { 'type': 'VECTOR',\n",
      "                                  'vectorKnowledgeBaseConfiguration': { 'embeddingModelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1'}},\n",
      "  'knowledgeBaseId': 'NE0M3BPNVV',\n",
      "  'name': 'bedrock-sample-knowledge-base-595',\n",
      "  'roleArn': 'arn:aws:iam::194722403835:role/AmazonBedrockExecutionRoleForKnowledgeBase_583',\n",
      "  'status': 'CREATING',\n",
      "  'storageConfiguration': { 'opensearchServerlessConfiguration': { 'collectionArn': 'arn:aws:aoss:us-east-1:194722403835:collection/sih12shy7voec25uj5gc',\n",
      "                                                                   'fieldMapping': { 'metadataField': 'text-metadata',\n",
      "                                                                                     'textField': 'text',\n",
      "                                                                                     'vectorField': 'vector'},\n",
      "                                                                   'vectorIndexName': 'bedrock-sample-index-595'},\n",
      "                            'type': 'OPENSEARCH_SERVERLESS'},\n",
      "  'updatedAt': datetime.datetime(2024, 10, 8, 21, 49, 40, 803792, tzinfo=tzutc())}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(kb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8b60321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get KnowledgeBase \n",
    "get_kb_response = bedrock_agent_client.get_knowledge_base(knowledgeBaseId = kb['knowledgeBaseId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40ec79b",
   "metadata": {},
   "source": [
    "Next we need to create a data source, which will be associated with the knowledge base created above. Once the data source is ready, we can then start to ingest the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c13b0ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'createdAt': datetime.datetime(2024, 10, 8, 21, 50, 14, 803247, tzinfo=tzutc()),\n",
      "  'dataDeletionPolicy': 'DELETE',\n",
      "  'dataSourceConfiguration': { 's3Configuration': { 'bucketArn': 'arn:aws:s3:::vlrscraperbucket'},\n",
      "                               'type': 'S3'},\n",
      "  'dataSourceId': 'A4TJYABDP0',\n",
      "  'description': 'Amazon shareholder letter knowledge base.',\n",
      "  'knowledgeBaseId': 'NE0M3BPNVV',\n",
      "  'name': 'bedrock-sample-knowledge-base-595',\n",
      "  'status': 'AVAILABLE',\n",
      "  'updatedAt': datetime.datetime(2024, 10, 8, 21, 50, 14, 803247, tzinfo=tzutc()),\n",
      "  'vectorIngestionConfiguration': { 'chunkingConfiguration': { 'chunkingStrategy': 'FIXED_SIZE',\n",
      "                                                               'fixedSizeChunkingConfiguration': { 'maxTokens': 512,\n",
      "                                                                                                   'overlapPercentage': 20}}}}\n"
     ]
    }
   ],
   "source": [
    "# Create a DataSource in KnowledgeBase \n",
    "create_ds_response = bedrock_agent_client.create_data_source(\n",
    "    name = name,\n",
    "    description = description,\n",
    "    knowledgeBaseId = kb['knowledgeBaseId'],\n",
    "    dataSourceConfiguration = {\n",
    "        \"type\": \"S3\",\n",
    "        \"s3Configuration\":s3Configuration\n",
    "    },\n",
    "    vectorIngestionConfiguration = {\n",
    "        \"chunkingConfiguration\": chunkingStrategyConfiguration\n",
    "    }\n",
    ")\n",
    "ds = create_ds_response[\"dataSource\"]\n",
    "pp.pprint(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e744591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\r"
     ]
    }
   ],
   "source": [
    "# Start an ingestion job\n",
    "interactive_sleep(30)\n",
    "start_job_response = bedrock_agent_client.start_ingestion_job(knowledgeBaseId = kb['knowledgeBaseId'], dataSourceId = ds[\"dataSourceId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c09051cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'dataSourceId': 'A4TJYABDP0',\n",
      "  'ingestionJobId': '0ITWGOSJQZ',\n",
      "  'knowledgeBaseId': 'NE0M3BPNVV',\n",
      "  'startedAt': datetime.datetime(2024, 10, 8, 21, 50, 49, 299892, tzinfo=tzutc()),\n",
      "  'statistics': { 'numberOfDocumentsDeleted': 0,\n",
      "                  'numberOfDocumentsFailed': 0,\n",
      "                  'numberOfDocumentsScanned': 0,\n",
      "                  'numberOfMetadataDocumentsModified': 0,\n",
      "                  'numberOfMetadataDocumentsScanned': 0,\n",
      "                  'numberOfModifiedDocumentsIndexed': 0,\n",
      "                  'numberOfNewDocumentsIndexed': 0},\n",
      "  'status': 'STARTING',\n",
      "  'updatedAt': datetime.datetime(2024, 10, 8, 21, 50, 49, 299892, tzinfo=tzutc())}\n"
     ]
    }
   ],
   "source": [
    "job = start_job_response[\"ingestionJob\"]\n",
    "pp.pprint(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9f383f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'dataSourceId': 'A4TJYABDP0',\n",
      "  'ingestionJobId': '0ITWGOSJQZ',\n",
      "  'knowledgeBaseId': 'NE0M3BPNVV',\n",
      "  'startedAt': datetime.datetime(2024, 10, 8, 21, 50, 49, 299892, tzinfo=tzutc()),\n",
      "  'statistics': { 'numberOfDocumentsDeleted': 0,\n",
      "                  'numberOfDocumentsFailed': 0,\n",
      "                  'numberOfDocumentsScanned': 2,\n",
      "                  'numberOfMetadataDocumentsModified': 0,\n",
      "                  'numberOfMetadataDocumentsScanned': 0,\n",
      "                  'numberOfModifiedDocumentsIndexed': 0,\n",
      "                  'numberOfNewDocumentsIndexed': 2},\n",
      "  'status': 'COMPLETE',\n",
      "  'updatedAt': datetime.datetime(2024, 10, 8, 21, 52, 26, 353344, tzinfo=tzutc())}\n"
     ]
    }
   ],
   "source": [
    "# Get job \n",
    "while(job['status']!='COMPLETE' ):\n",
    "    get_job_response = bedrock_agent_client.get_ingestion_job(\n",
    "      knowledgeBaseId = kb['knowledgeBaseId'],\n",
    "        dataSourceId = ds[\"dataSourceId\"],\n",
    "        ingestionJobId = job[\"ingestionJobId\"]\n",
    "  )\n",
    "    job = get_job_response[\"ingestionJob\"]\n",
    "    \n",
    "    interactive_sleep(30)\n",
    "\n",
    "pp.pprint(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c746cd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NE0M3BPNVV'\n"
     ]
    }
   ],
   "source": [
    "# Print the knowledge base Id in bedrock, that corresponds to the Opensearch index in the collection we created before, we will use it for the invocation later\n",
    "kb_id = kb[\"knowledgeBaseId\"]\n",
    "pp.pprint(kb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16e2b41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'kb_id' (str)\n"
     ]
    }
   ],
   "source": [
    "# keep the kb_id for invocation later in the invoke request\n",
    "%store kb_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa82aa15",
   "metadata": {},
   "source": [
    "# Test the knowledge base\n",
    "\n",
    "## Note: If you plan to run any following notebooks, you can skip this section\n",
    "\n",
    "## Using RetrieveAndGenerate API\n",
    "\n",
    "Behind the scenes, RetrieveAndGenerate API converts queries into embeddings, searches the knowledge base, and then augments the foundation model prompt with the search results as context information and returns the FM-generated response to the question. For multi-turn conversations, Knowledge Bases manage short-term memory of the conversation to provide more contextual results.\n",
    "\n",
    "The output of the RetrieveAndGenerate API includes the generated response, source attribution as well as the retrieved text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc8fc713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out KB using RetrieveAndGenerate API\n",
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\", region_name=region_name)\n",
    "# Lets see how different Anthropic Claude 3 models responds to the input text we provide\n",
    "claude_model_ids = [ [\"Claude 3 Sonnet\", \"anthropic.claude-3-sonnet-20240229-v1:0\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd8b7758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_bedrock_llm_with_knowledge_base(query: str, model_arn: str, kb_id: str) -> str:\n",
    "    response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "        input={\n",
    "            'text': query\n",
    "        },\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            'type': 'KNOWLEDGE_BASE',\n",
    "            'knowledgeBaseConfiguration': {\n",
    "                'knowledgeBaseId': kb_id,\n",
    "                'modelArn': model_arn\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f704503a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Generated using Claude 3 Sonnet:\n",
      "('One team with agents that do not overlap is:\\n'\n",
      " '\\n'\n",
      " 'Odessaca: Omen, Sage, Breach, Raze\\n'\n",
      " 'eva: Sova, Gekko, Skye\\n'\n",
      " 'Kazler: Jett, Raze, Deadlock\\n'\n",
      " 'Nats: Viper, Astra, Brimstone\\n'\n",
      " 'chloric: Raze, Sova\\n'\n",
      " '\\n'\n",
      " 'This team covers all agents without any duplicates.')\n"
     ]
    }
   ],
   "source": [
    "query = \"give a team with agents that dont overlap\"\n",
    "\n",
    "for model_id in claude_model_ids:\n",
    "    model_arn = f'arn:aws:bedrock:{region_name}::foundation-model/{model_id[1]}'\n",
    "    response = ask_bedrock_llm_with_knowledge_base(query, model_arn, kb_id)\n",
    "    generated_text = response['output']['text']\n",
    "    citations = response[\"citations\"]\n",
    "    contexts = []\n",
    "    for citation in citations:\n",
    "        retrievedReferences = citation[\"retrievedReferences\"]\n",
    "        for reference in retrievedReferences:\n",
    "            contexts.append(reference[\"content\"][\"text\"])\n",
    "    print(f\"---------- Generated using {model_id[0]}:\")\n",
    "    pp.pprint(generated_text )\n",
    "    #print(f'---------- The citations for the response generated by {model_id[0]}:')\n",
    "    #pp.pprint(contexts)\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aeda99",
   "metadata": {},
   "source": [
    "# Retrieve API\n",
    "\n",
    "Retrieve API converts user queries into embeddings, searches the knowledge base, and returns the relevant results, giving you more control to build custom workﬂows on top of the semantic search results. The output of the Retrieve API includes the the retrieved text chunks, the location type and URI of the source data, as well as the relevance scores of the retrievals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "341361e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve api for fetching only the relevant context.\n",
    "relevant_documents = bedrock_agent_runtime_client.retrieve(\n",
    "    retrievalQuery= {\n",
    "        'text': query\n",
    "    },\n",
    "    knowledgeBaseId=kb_id,\n",
    "    retrievalConfiguration= {\n",
    "        'vectorSearchConfiguration': {\n",
    "            'numberOfResults': 3 # will fetch top 3 documents which matches closely with the query.\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42c435af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ { 'content': { 'text': 'Amazon has been using machine learning extensively '\n",
      "                         'for 25 years, employing it in everything from '\n",
      "                         'personalized ecommerce recommendations, to '\n",
      "                         'fulfillment center pick paths, to drones for Prime '\n",
      "                         'Air, to Alexa, to the many machine learning services '\n",
      "                         'AWS offers (where AWS has the broadest machine '\n",
      "                         'learning functionality and customer base of any '\n",
      "                         'cloud provider). More recently, a newer form of '\n",
      "                         'machine learning, called Generative AI, has burst '\n",
      "                         'onto the scene and promises to significantly '\n",
      "                         'accelerate machine learning adoption. Generative AI '\n",
      "                         'is based on very Large Language Models (trained on '\n",
      "                         'up to hundreds of billions of parameters, and '\n",
      "                         'growing), across expansive datasets, and has '\n",
      "                         'radically general and broad recall and learning '\n",
      "                         'capabilities. We have been working on our own LLMs '\n",
      "                         'for a while now, believe it will transform and '\n",
      "                         'improve virtually every customer experience, and '\n",
      "                         'will continue to invest substantially in these '\n",
      "                         'models across all of our consumer, seller, brand, '\n",
      "                         'and creator experiences. Additionally, as we’ve done '\n",
      "                         'for years in AWS, we’re democratizing this '\n",
      "                         'technology so companies of all sizes can leverage '\n",
      "                         'Generative AI. AWS is offering the most '\n",
      "                         'price-performant machine learning chips in Trainium '\n",
      "                         'and Inferentia so small and large companies can '\n",
      "                         'afford to train and run their LLMs in production. We '\n",
      "                         'enable companies to choose from various LLMs and '\n",
      "                         'build applications with all of the AWS security, '\n",
      "                         'privacy and other features that customers are '\n",
      "                         'accustomed to using. And, we’re delivering '\n",
      "                         'applications like AWS’s CodeWhisperer, which '\n",
      "                         'revolutionizes        developer productivity by '\n",
      "                         'generating code suggestions in real time. I could '\n",
      "                         'write an entire letter on LLMs and Generative AI as '\n",
      "                         'I think they will be that transformative, but I’ll '\n",
      "                         'leave that for a future letter. Let’s just say that '\n",
      "                         'LLMs and Generative AI are going to be a big deal '\n",
      "                         'for customers, our shareholders, and Amazon.   So, '\n",
      "                         'in closing, I’m optimistic that we’ll emerge from '\n",
      "                         'this challenging macroeconomic time in a stronger '\n",
      "                         'position than when we entered it. There are several '\n",
      "                         'reasons for it and I’ve mentioned many of them '\n",
      "                         'above. But, there are two relatively simple '\n",
      "                         'statistics that underline our immense future '\n",
      "                         'opportunity. While we have a consumer business '\n",
      "                         'that’s $434B in 2022, the vast majority of total '\n",
      "                         'market segment share in global retail still resides '\n",
      "                         'in physical stores (roughly 80%). And, it’s a '\n",
      "                         'similar story for Global IT spending, where we have '\n",
      "                         'AWS revenue of $80B in 2022, with about 90% of '\n",
      "                         'Global IT spending still on-premises and yet to '\n",
      "                         'migrate to the cloud.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-east-1-194722403835/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3A1M0eXZIBhGxTQSFs8-s4',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'D3K2AJRT1I',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-east-1-194722403835/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "    'score': 0.6664225},\n",
      "  { 'content': { 'text': 'Our Inferentia2 chip, which just launched, offers up '\n",
      "                         'to four times higher throughput and ten times lower '\n",
      "                         'latency than our first Inferentia processor. With '\n",
      "                         'the enormous upcoming growth in machine learning, '\n",
      "                         'customers will be able to get a lot more done with '\n",
      "                         'AWS’s training and inference chips at a '\n",
      "                         'significantly lower cost. We’re not close to being '\n",
      "                         'done innovating here, and this long-term investment '\n",
      "                         'should prove fruitful for both customers and AWS. '\n",
      "                         'AWS is still in the early stages of its evolution, '\n",
      "                         'and has a chance for unusual growth in the next '\n",
      "                         'decade.   Similarly high potential, Amazon’s '\n",
      "                         'Advertising business is uniquely effective for '\n",
      "                         'brands, which is part of why it continues to grow at '\n",
      "                         'a brisk clip. Akin to physical retailers’ '\n",
      "                         'advertising businesses selling shelf space, end- '\n",
      "                         'caps, and placement in their circulars, our '\n",
      "                         'sponsored products and brands offerings have been an '\n",
      "                         'integral part        of the Amazon shopping '\n",
      "                         'experience for more than a decade. However, unlike '\n",
      "                         'physical retailers, Amazon can tailor these '\n",
      "                         'sponsored products to be relevant to what customers '\n",
      "                         'are searching for given what we know about shopping '\n",
      "                         'behaviors and our very deep investment in machine '\n",
      "                         'learning algorithms. This leads to advertising '\n",
      "                         'that’s more useful for customers; and as a result, '\n",
      "                         'performs better for brands. This is part of why our '\n",
      "                         'Advertising revenue has continued to grow rapidly '\n",
      "                         '(23% YoY in Q4 2022, 25% YoY overall for 2022 on a '\n",
      "                         '$31B revenue base), even as most large '\n",
      "                         'advertising-focused businesses’ growth have slowed '\n",
      "                         'over the last several quarters.   We strive to be '\n",
      "                         'the best place for advertisers to build their '\n",
      "                         'brands. We have near and long-term opportunities '\n",
      "                         'that will help us achieve that mission. We’re '\n",
      "                         'continuing to make large investments in machine '\n",
      "                         'learning to keep honing our advertising selection '\n",
      "                         'algorithms. For the past couple of years, we’ve '\n",
      "                         'invested in building comprehensive, flexible, and '\n",
      "                         'durable planning and measurement solutions, giving '\n",
      "                         'marketers greater insight into advertising '\n",
      "                         'effectiveness. An example is Amazon Marketing Cloud '\n",
      "                         '(“AMC”). AMC is a “clean room” (i.e. secure digital '\n",
      "                         'environment) in which advertisers can run custom '\n",
      "                         'audience and campaign analytics across a range of '\n",
      "                         'first and third-party inputs, in a privacy-safe '\n",
      "                         'manner, to generate advertising and business '\n",
      "                         'insights to inform their broader marketing and sales '\n",
      "                         'strategies. The Advertising and AWS teams have '\n",
      "                         'collaborated to enable companies to store their data '\n",
      "                         'in AWS, operate securely in AMC with Amazon and '\n",
      "                         'other third-party data sources, perform analytics in '\n",
      "                         'AWS, and have the option to activate advertising on '\n",
      "                         'Amazon or third-party publishers through the Amazon '\n",
      "                         'Demand-Side Platform.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-east-1-194722403835/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3Azc0eXZIBhGxTQSFs8-s4',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'D3K2AJRT1I',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-east-1-194722403835/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "    'score': 0.54871696},\n",
      "  { 'content': { 'text': 'Imagine what they’ll be able to do with reliable '\n",
      "                         'connectivity, from people taking online education '\n",
      "                         'courses, using financial services, starting their '\n",
      "                         'own businesses, doing their shopping, enjoying '\n",
      "                         'entertainment, to businesses and governments '\n",
      "                         'improving their coverage, efficiency, and '\n",
      "                         'operations. Kuiper will deliver not only '\n",
      "                         'accessibility, but affordability. Our teams have '\n",
      "                         'developed low-cost antennas (i.e. customer '\n",
      "                         'terminals) that will lower the barriers to access. '\n",
      "                         'We recently unveiled the new terminals that will '\n",
      "                         'communicate with the satellites passing overhead, '\n",
      "                         'and we expect to be able to produce our standard '\n",
      "                         'residential version for less than $400 each. They’re '\n",
      "                         'small: 11 inches square, 1 inch thick, and weigh '\n",
      "                         'less than 5 pounds without their mounting bracket, '\n",
      "                         'but they deliver speeds up to 400 megabits per '\n",
      "                         'second. And they’re powered by Amazon-designed '\n",
      "                         'baseband chips. We’re preparing to launch two '\n",
      "                         'prototype satellites to test the entire end-to-end '\n",
      "                         'communications network this year, and plan to be in '\n",
      "                         'beta with commercial customers in 2024. The customer '\n",
      "                         'reaction to what we’ve shared thus far about Kuiper '\n",
      "                         'has been very positive, and we believe Kuiper '\n",
      "                         'represents a very large potential opportunity for '\n",
      "                         'Amazon. It also shares several similarities to AWS '\n",
      "                         'in that it’s capital intensive at the start, but has '\n",
      "                         'a large prospective consumer, enterprise, and '\n",
      "                         'government customer base, significant revenue and '\n",
      "                         'operating profit potential, and relatively few '\n",
      "                         'companies with the technical and inventive aptitude, '\n",
      "                         'as well as the investment hypothesis to go after '\n",
      "                         'it.   One final investment area that I’ll mention, '\n",
      "                         'that’s core to setting Amazon up to invent in every '\n",
      "                         'area of our business for many decades to come, and '\n",
      "                         'where we’re investing heavily is Large Language '\n",
      "                         'Models (“LLMs”) and Generative AI. Machine learning '\n",
      "                         'has been a technology with high promise for several '\n",
      "                         'decades, but it’s only been the last five to ten '\n",
      "                         'years that it’s started to be used more pervasively '\n",
      "                         'by companies. This shift was driven by several '\n",
      "                         'factors, including access to higher volumes of '\n",
      "                         'compute capacity at lower prices than was ever '\n",
      "                         'available. Amazon has been using machine learning '\n",
      "                         'extensively for 25 years, employing it in everything '\n",
      "                         'from personalized ecommerce recommendations, to '\n",
      "                         'fulfillment center pick paths, to drones for Prime '\n",
      "                         'Air, to Alexa, to the many machine learning services '\n",
      "                         'AWS offers (where AWS has the broadest machine '\n",
      "                         'learning functionality and customer base of any '\n",
      "                         'cloud provider). More recently, a newer form of '\n",
      "                         'machine learning, called Generative AI, has burst '\n",
      "                         'onto the scene and promises to significantly '\n",
      "                         'accelerate machine learning adoption.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-east-1-194722403835/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3A080eXZIBhGxTQSFs8-s4',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'D3K2AJRT1I',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-east-1-194722403835/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "    'score': 0.53047615}]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(relevant_documents[\"retrievalResults\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d75a79",
   "metadata": {},
   "source": [
    "# Building Q&A application using Knowledge Bases for Amazon Bedrock - RetrieveAndGenerate API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4153eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76dc8c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pprint\n",
    "from botocore.client import Config\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\",\n",
    "                              config=bedrock_config)\n",
    "boto3_session = boto3.session.Session()\n",
    "region_name = boto3_session.region_name\n",
    "\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\" # try with both claude 3 Haiku as well as claude 3 Sonnet. for claude 3 Sonnet - \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "region_id = region_name # replace it with the region you're running sagemaker notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eedec05",
   "metadata": {},
   "source": [
    "# RetreiveAndGenerate API\n",
    "\n",
    "Behind the scenes, RetrieveAndGenerate API converts queries into embeddings, searches the knowledge base, and then augments the foundation model prompt with the search results as context information and returns the FM-generated response to the question. For multi-turn conversations, Knowledge Bases manage short-term memory of the conversation to provide more contextual results.\n",
    "\n",
    "The output of the RetrieveAndGenerate API includes the generated response, source attribution as well as the retrieved text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccd6eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveAndGenerate(input, kbId, sessionId=None, model_id = \"anthropic.claude-3-haiku-20240307-v1:0\", region_id = \"us-east-1\"):\n",
    "    model_arn = f'arn:aws:bedrock:{region_id}::foundation-model/{model_id}'\n",
    "    if sessionId:\n",
    "        return bedrock_agent_client.retrieve_and_generate(\n",
    "            input={\n",
    "                'text': input\n",
    "            },\n",
    "            retrieveAndGenerateConfiguration={\n",
    "                'type': 'KNOWLEDGE_BASE',\n",
    "                'knowledgeBaseConfiguration': {\n",
    "                    'knowledgeBaseId': kbId,\n",
    "                    'modelArn': model_arn\n",
    "                }\n",
    "            },\n",
    "            sessionId=sessionId\n",
    "        )\n",
    "    else:\n",
    "        return bedrock_agent_client.retrieve_and_generate(\n",
    "            input={\n",
    "                'text': input\n",
    "            },\n",
    "            retrieveAndGenerateConfiguration={\n",
    "                'type': 'KNOWLEDGE_BASE',\n",
    "                'knowledgeBaseConfiguration': {\n",
    "                    'knowledgeBaseId': kbId,\n",
    "                    'modelArn': model_arn\n",
    "                }\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b319efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Amazon has been investing heavily in large language models (LLMs) and '\n",
      " 'generative AI, which they believe will significantly accelerate the adoption '\n",
      " 'of machine learning across their various businesses. Specifically: Amazon '\n",
      " 'has been working on developing its own LLMs, which they believe will '\n",
      " 'transform and improve virtually every customer experience across their '\n",
      " 'consumer, seller, brand, and creator offerings. Additionally, Amazon is '\n",
      " 'democratizing this technology through AWS, offering the most '\n",
      " 'price-performant machine learning chips in Trainium and Inferentia so '\n",
      " 'companies of all sizes can afford to train and run their LLMs in production. '\n",
      " 'AWS is also enabling companies to choose from various LLMs and build '\n",
      " \"applications with AWS's security, privacy, and other features.\")\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Amazon's doing in the field of generative AI?\"\n",
    "response = retrieveAndGenerate(query, kb_id,model_id=model_id,region_id=region_id)\n",
    "generated_text = response['output']['text']\n",
    "pp.pprint(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6dbd088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 'Amazon has been using machine learning extensively for 25 years, employing '\n",
      "  'it in everything from personalized ecommerce recommendations, to '\n",
      "  'fulfillment center pick paths, to drones for Prime Air, to Alexa, to the '\n",
      "  'many machine learning services AWS offers (where AWS has the broadest '\n",
      "  'machine learning functionality and customer base of any cloud provider). '\n",
      "  'More recently, a newer form of machine learning, called Generative AI, has '\n",
      "  'burst onto the scene and promises to significantly accelerate machine '\n",
      "  'learning adoption. Generative AI is based on very Large Language Models '\n",
      "  '(trained on up to hundreds of billions of parameters, and growing), across '\n",
      "  'expansive datasets, and has radically general and broad recall and learning '\n",
      "  'capabilities. We have been working on our own LLMs for a while now, believe '\n",
      "  'it will transform and improve virtually every customer experience, and will '\n",
      "  'continue to invest substantially in these models across all of our '\n",
      "  'consumer, seller, brand, and creator experiences. Additionally, as we’ve '\n",
      "  'done for years in AWS, we’re democratizing this technology so companies of '\n",
      "  'all sizes can leverage Generative AI. AWS is offering the most '\n",
      "  'price-performant machine learning chips in Trainium and Inferentia so small '\n",
      "  'and large companies can afford to train and run their LLMs in production. '\n",
      "  'We enable companies to choose from various LLMs and build applications with '\n",
      "  'all of the AWS security, privacy and other features that customers are '\n",
      "  'accustomed to using. And, we’re delivering applications like AWS’s '\n",
      "  'CodeWhisperer, which revolutionizes        developer productivity by '\n",
      "  'generating code suggestions in real time. I could write an entire letter on '\n",
      "  'LLMs and Generative AI as I think they will be that transformative, but '\n",
      "  'I’ll leave that for a future letter. Let’s just say that LLMs and '\n",
      "  'Generative AI are going to be a big deal for customers, our shareholders, '\n",
      "  'and Amazon.   So, in closing, I’m optimistic that we’ll emerge from this '\n",
      "  'challenging macroeconomic time in a stronger position than when we entered '\n",
      "  'it. There are several reasons for it and I’ve mentioned many of them above. '\n",
      "  'But, there are two relatively simple statistics that underline our immense '\n",
      "  'future opportunity. While we have a consumer business that’s $434B in 2022, '\n",
      "  'the vast majority of total market segment share in global retail still '\n",
      "  'resides in physical stores (roughly 80%). And, it’s a similar story for '\n",
      "  'Global IT spending, where we have AWS revenue of $80B in 2022, with about '\n",
      "  '90% of Global IT spending still on-premises and yet to migrate to the '\n",
      "  'cloud.',\n",
      "  'Amazon has been using machine learning extensively for 25 years, employing '\n",
      "  'it in everything from personalized ecommerce recommendations, to '\n",
      "  'fulfillment center pick paths, to drones for Prime Air, to Alexa, to the '\n",
      "  'many machine learning services AWS offers (where AWS has the broadest '\n",
      "  'machine learning functionality and customer base of any cloud provider). '\n",
      "  'More recently, a newer form of machine learning, called Generative AI, has '\n",
      "  'burst onto the scene and promises to significantly accelerate machine '\n",
      "  'learning adoption. Generative AI is based on very Large Language Models '\n",
      "  '(trained on up to hundreds of billions of parameters, and growing), across '\n",
      "  'expansive datasets, and has radically general and broad recall and learning '\n",
      "  'capabilities. We have been working on our own LLMs for a while now, believe '\n",
      "  'it will transform and improve virtually every customer experience, and will '\n",
      "  'continue to invest substantially in these models across all of our '\n",
      "  'consumer, seller, brand, and creator experiences. Additionally, as we’ve '\n",
      "  'done for years in AWS, we’re democratizing this technology so companies of '\n",
      "  'all sizes can leverage Generative AI. AWS is offering the most '\n",
      "  'price-performant machine learning chips in Trainium and Inferentia so small '\n",
      "  'and large companies can afford to train and run their LLMs in production. '\n",
      "  'We enable companies to choose from various LLMs and build applications with '\n",
      "  'all of the AWS security, privacy and other features that customers are '\n",
      "  'accustomed to using. And, we’re delivering applications like AWS’s '\n",
      "  'CodeWhisperer, which revolutionizes        developer productivity by '\n",
      "  'generating code suggestions in real time. I could write an entire letter on '\n",
      "  'LLMs and Generative AI as I think they will be that transformative, but '\n",
      "  'I’ll leave that for a future letter. Let’s just say that LLMs and '\n",
      "  'Generative AI are going to be a big deal for customers, our shareholders, '\n",
      "  'and Amazon.   So, in closing, I’m optimistic that we’ll emerge from this '\n",
      "  'challenging macroeconomic time in a stronger position than when we entered '\n",
      "  'it. There are several reasons for it and I’ve mentioned many of them above. '\n",
      "  'But, there are two relatively simple statistics that underline our immense '\n",
      "  'future opportunity. While we have a consumer business that’s $434B in 2022, '\n",
      "  'the vast majority of total market segment share in global retail still '\n",
      "  'resides in physical stores (roughly 80%). And, it’s a similar story for '\n",
      "  'Global IT spending, where we have AWS revenue of $80B in 2022, with about '\n",
      "  '90% of Global IT spending still on-premises and yet to migrate to the '\n",
      "  'cloud.']\n"
     ]
    }
   ],
   "source": [
    "citations = response[\"citations\"]\n",
    "contexts = []\n",
    "for citation in citations:\n",
    "    retrievedReferences = citation[\"retrievedReferences\"]\n",
    "    for reference in retrievedReferences:\n",
    "         contexts.append(reference[\"content\"][\"text\"])\n",
    "\n",
    "pp.pprint(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef05c3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement langchain-aws=='0.1.17' (from versions: 0.1.0rc0, 0.1.0, 0.1.1, 0.1.2, 0.1.3, 0.1.4, 0.1.5, 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.1.10, 0.1.11, 0.1.12, 0.1.13, 0.1.14, 0.1.15, 0.1.16, 0.1.17, 0.1.18, 0.2.0.dev1, 0.2.0, 0.2.1, 0.2.2)\n",
      "ERROR: No matching distribution found for langchain-aws=='0.1.17'\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U langchain-aws=='0.1.17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e723866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: boto3\n",
      "Version: 1.35.29\n",
      "Summary: The AWS SDK for Python\n",
      "Home-page: https://github.com/boto/boto3\n",
      "Author: Amazon Web Services\n",
      "Author-email: \n",
      "License: Apache License 2.0\n",
      "Location: c:\\users\\deepm\\anaconda3\\lib\\site-packages\n",
      "Requires: botocore, jmespath, s3transfer\n",
      "Required-by: \n",
      "---\n",
      "Name: botocore\n",
      "Version: 1.35.29\n",
      "Summary: Low-level, data-driven core of boto 3.\n",
      "Home-page: https://github.com/boto/botocore\n",
      "Author: Amazon Web Services\n",
      "Author-email: \n",
      "License: Apache License 2.0\n",
      "Location: c:\\users\\deepm\\anaconda3\\lib\\site-packages\n",
      "Requires: urllib3, jmespath, python-dateutil\n",
      "Required-by: s3transfer, boto3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\deepm\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip show boto3 botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d883d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d440448c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8941866c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pprint\n",
    "from botocore.client import Config\n",
    "import json\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime', region_name = region)\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\",\n",
    "                              config=bedrock_config, region_name = region)\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64094df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, kbId, numberOfResults=5):\n",
    "    return bedrock_agent_client.retrieve(\n",
    "        retrievalQuery= {\n",
    "            'text': query\n",
    "        },\n",
    "        knowledgeBaseId=kbId,\n",
    "        retrievalConfiguration= {\n",
    "            'vectorSearchConfiguration': {\n",
    "                'numberOfResults': numberOfResults,\n",
    "                'overrideSearchType': \"HYBRID\", # optional\n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0edc4ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ { 'content': { 'text': 'Imagine what they’ll be able to do with reliable '\n",
      "                         'connectivity, from people taking online education '\n",
      "                         'courses, using financial services, starting their '\n",
      "                         'own businesses, doing their shopping, enjoying '\n",
      "                         'entertainment, to businesses and governments '\n",
      "                         'improving their coverage, efficiency, and '\n",
      "                         'operations. Kuiper will deliver not only '\n",
      "                         'accessibility, but affordability. Our teams have '\n",
      "                         'developed low-cost antennas (i.e. customer '\n",
      "                         'terminals) that will lower the barriers to access. '\n",
      "                         'We recently unveiled the new terminals that will '\n",
      "                         'communicate with the satellites passing overhead, '\n",
      "                         'and we expect to be able to produce our standard '\n",
      "                         'residential version for less than $400 each. They’re '\n",
      "                         'small: 11 inches square, 1 inch thick, and weigh '\n",
      "                         'less than 5 pounds without their mounting bracket, '\n",
      "                         'but they deliver speeds up to 400 megabits per '\n",
      "                         'second. And they’re powered by Amazon-designed '\n",
      "                         'baseband chips. We’re preparing to launch two '\n",
      "                         'prototype satellites to test the entire end-to-end '\n",
      "                         'communications network this year, and plan to be in '\n",
      "                         'beta with commercial customers in 2024. The customer '\n",
      "                         'reaction to what we’ve shared thus far about Kuiper '\n",
      "                         'has been very positive, and we believe Kuiper '\n",
      "                         'represents a very large potential opportunity for '\n",
      "                         'Amazon. It also shares several similarities to AWS '\n",
      "                         'in that it’s capital intensive at the start, but has '\n",
      "                         'a large prospective consumer, enterprise, and '\n",
      "                         'government customer base, significant revenue and '\n",
      "                         'operating profit potential, and relatively few '\n",
      "                         'companies with the technical and inventive aptitude, '\n",
      "                         'as well as the investment hypothesis to go after '\n",
      "                         'it.   One final investment area that I’ll mention, '\n",
      "                         'that’s core to setting Amazon up to invent in every '\n",
      "                         'area of our business for many decades to come, and '\n",
      "                         'where we’re investing heavily is Large Language '\n",
      "                         'Models (“LLMs”) and Generative AI. Machine learning '\n",
      "                         'has been a technology with high promise for several '\n",
      "                         'decades, but it’s only been the last five to ten '\n",
      "                         'years that it’s started to be used more pervasively '\n",
      "                         'by companies. This shift was driven by several '\n",
      "                         'factors, including access to higher volumes of '\n",
      "                         'compute capacity at lower prices than was ever '\n",
      "                         'available. Amazon has been using machine learning '\n",
      "                         'extensively for 25 years, employing it in everything '\n",
      "                         'from personalized ecommerce recommendations, to '\n",
      "                         'fulfillment center pick paths, to drones for Prime '\n",
      "                         'Air, to Alexa, to the many machine learning services '\n",
      "                         'AWS offers (where AWS has the broadest machine '\n",
      "                         'learning functionality and customer base of any '\n",
      "                         'cloud provider). More recently, a newer form of '\n",
      "                         'machine learning, called Generative AI, has burst '\n",
      "                         'onto the scene and promises to significantly '\n",
      "                         'accelerate machine learning adoption.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-east-1-194722403835/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3A080eXZIBhGxTQSFs8-s4',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'D3K2AJRT1I',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-east-1-194722403835/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "    'score': 0.6663662},\n",
      "  { 'content': { 'text': 'Amazon has been using machine learning extensively '\n",
      "                         'for 25 years, employing it in everything from '\n",
      "                         'personalized ecommerce recommendations, to '\n",
      "                         'fulfillment center pick paths, to drones for Prime '\n",
      "                         'Air, to Alexa, to the many machine learning services '\n",
      "                         'AWS offers (where AWS has the broadest machine '\n",
      "                         'learning functionality and customer base of any '\n",
      "                         'cloud provider). More recently, a newer form of '\n",
      "                         'machine learning, called Generative AI, has burst '\n",
      "                         'onto the scene and promises to significantly '\n",
      "                         'accelerate machine learning adoption. Generative AI '\n",
      "                         'is based on very Large Language Models (trained on '\n",
      "                         'up to hundreds of billions of parameters, and '\n",
      "                         'growing), across expansive datasets, and has '\n",
      "                         'radically general and broad recall and learning '\n",
      "                         'capabilities. We have been working on our own LLMs '\n",
      "                         'for a while now, believe it will transform and '\n",
      "                         'improve virtually every customer experience, and '\n",
      "                         'will continue to invest substantially in these '\n",
      "                         'models across all of our consumer, seller, brand, '\n",
      "                         'and creator experiences. Additionally, as we’ve done '\n",
      "                         'for years in AWS, we’re democratizing this '\n",
      "                         'technology so companies of all sizes can leverage '\n",
      "                         'Generative AI. AWS is offering the most '\n",
      "                         'price-performant machine learning chips in Trainium '\n",
      "                         'and Inferentia so small and large companies can '\n",
      "                         'afford to train and run their LLMs in production. We '\n",
      "                         'enable companies to choose from various LLMs and '\n",
      "                         'build applications with all of the AWS security, '\n",
      "                         'privacy and other features that customers are '\n",
      "                         'accustomed to using. And, we’re delivering '\n",
      "                         'applications like AWS’s CodeWhisperer, which '\n",
      "                         'revolutionizes        developer productivity by '\n",
      "                         'generating code suggestions in real time. I could '\n",
      "                         'write an entire letter on LLMs and Generative AI as '\n",
      "                         'I think they will be that transformative, but I’ll '\n",
      "                         'leave that for a future letter. Let’s just say that '\n",
      "                         'LLMs and Generative AI are going to be a big deal '\n",
      "                         'for customers, our shareholders, and Amazon.   So, '\n",
      "                         'in closing, I’m optimistic that we’ll emerge from '\n",
      "                         'this challenging macroeconomic time in a stronger '\n",
      "                         'position than when we entered it. There are several '\n",
      "                         'reasons for it and I’ve mentioned many of them '\n",
      "                         'above. But, there are two relatively simple '\n",
      "                         'statistics that underline our immense future '\n",
      "                         'opportunity. While we have a consumer business '\n",
      "                         'that’s $434B in 2022, the vast majority of total '\n",
      "                         'market segment share in global retail still resides '\n",
      "                         'in physical stores (roughly 80%). And, it’s a '\n",
      "                         'similar story for Global IT spending, where we have '\n",
      "                         'AWS revenue of $80B in 2022, with about 90% of '\n",
      "                         'Global IT spending still on-premises and yet to '\n",
      "                         'migrate to the cloud.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-east-1-194722403835/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3A1M0eXZIBhGxTQSFs8-s4',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'D3K2AJRT1I',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-east-1-194722403835/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "    'score': 0.6663662},\n",
      "  { 'content': { 'text': 'Our Inferentia2 chip, which just launched, offers up '\n",
      "                         'to four times higher throughput and ten times lower '\n",
      "                         'latency than our first Inferentia processor. With '\n",
      "                         'the enormous upcoming growth in machine learning, '\n",
      "                         'customers will be able to get a lot more done with '\n",
      "                         'AWS’s training and inference chips at a '\n",
      "                         'significantly lower cost. We’re not close to being '\n",
      "                         'done innovating here, and this long-term investment '\n",
      "                         'should prove fruitful for both customers and AWS. '\n",
      "                         'AWS is still in the early stages of its evolution, '\n",
      "                         'and has a chance for unusual growth in the next '\n",
      "                         'decade.   Similarly high potential, Amazon’s '\n",
      "                         'Advertising business is uniquely effective for '\n",
      "                         'brands, which is part of why it continues to grow at '\n",
      "                         'a brisk clip. Akin to physical retailers’ '\n",
      "                         'advertising businesses selling shelf space, end- '\n",
      "                         'caps, and placement in their circulars, our '\n",
      "                         'sponsored products and brands offerings have been an '\n",
      "                         'integral part        of the Amazon shopping '\n",
      "                         'experience for more than a decade. However, unlike '\n",
      "                         'physical retailers, Amazon can tailor these '\n",
      "                         'sponsored products to be relevant to what customers '\n",
      "                         'are searching for given what we know about shopping '\n",
      "                         'behaviors and our very deep investment in machine '\n",
      "                         'learning algorithms. This leads to advertising '\n",
      "                         'that’s more useful for customers; and as a result, '\n",
      "                         'performs better for brands. This is part of why our '\n",
      "                         'Advertising revenue has continued to grow rapidly '\n",
      "                         '(23% YoY in Q4 2022, 25% YoY overall for 2022 on a '\n",
      "                         '$31B revenue base), even as most large '\n",
      "                         'advertising-focused businesses’ growth have slowed '\n",
      "                         'over the last several quarters.   We strive to be '\n",
      "                         'the best place for advertisers to build their '\n",
      "                         'brands. We have near and long-term opportunities '\n",
      "                         'that will help us achieve that mission. We’re '\n",
      "                         'continuing to make large investments in machine '\n",
      "                         'learning to keep honing our advertising selection '\n",
      "                         'algorithms. For the past couple of years, we’ve '\n",
      "                         'invested in building comprehensive, flexible, and '\n",
      "                         'durable planning and measurement solutions, giving '\n",
      "                         'marketers greater insight into advertising '\n",
      "                         'effectiveness. An example is Amazon Marketing Cloud '\n",
      "                         '(“AMC”). AMC is a “clean room” (i.e. secure digital '\n",
      "                         'environment) in which advertisers can run custom '\n",
      "                         'audience and campaign analytics across a range of '\n",
      "                         'first and third-party inputs, in a privacy-safe '\n",
      "                         'manner, to generate advertising and business '\n",
      "                         'insights to inform their broader marketing and sales '\n",
      "                         'strategies. The Advertising and AWS teams have '\n",
      "                         'collaborated to enable companies to store their data '\n",
      "                         'in AWS, operate securely in AMC with Amazon and '\n",
      "                         'other third-party data sources, perform analytics in '\n",
      "                         'AWS, and have the option to activate advertising on '\n",
      "                         'Amazon or third-party publishers through the Amazon '\n",
      "                         'Demand-Side Platform.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-east-1-194722403835/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3Azc0eXZIBhGxTQSFs8-s4',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'D3K2AJRT1I',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-east-1-194722403835/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "    'score': 0.54780453},\n",
      "  { 'content': { 'text': 'We believe that we’ve only scratched the surface of '\n",
      "                         'what’s possible to date, and plan to keep building '\n",
      "                         'the features our business customers tell us they '\n",
      "                         'need and want.   While many brands and merchants '\n",
      "                         'successfully sell their products on Amazon’s '\n",
      "                         'marketplace, there are also a large number of brands '\n",
      "                         'and sellers who have launched their own '\n",
      "                         'direct-to-consumer websites. One of the challenges '\n",
      "                         'for these merchants is driving conversion from views '\n",
      "                         'to purchases. We invented Buy with Prime to help '\n",
      "                         'with this challenge. Buy with Prime allows '\n",
      "                         'third-party brands and sellers to offer their '\n",
      "                         'products on their own websites to our large Amazon '\n",
      "                         'Prime membership, and offer those customers fast, '\n",
      "                         'free Prime shipping and seamless checkout with their '\n",
      "                         'Amazon account. Buy with Prime provides merchants '\n",
      "                         'several additional benefits, including Amazon '\n",
      "                         'handling the product storage, picking, packing, '\n",
      "                         'delivery, payment, and any returns, all through '\n",
      "                         'Amazon Pay and Fulfillment by Amazon. Buy with Prime '\n",
      "                         'has recently been made available to all US '\n",
      "                         'merchants; and so far, Buy with Prime has increased '\n",
      "                         'shopper conversion on third-party shopping sites by '\n",
      "                         '25% on average. Merchants are excited about '\n",
      "                         'converting more sales and fulfilling these shipments '\n",
      "                         'more easily, Prime members love that they can use '\n",
      "                         'their Prime benefits on more destinations, and Buy '\n",
      "                         'with Prime allows us to improve the shopping '\n",
      "                         'experience across more of the web.   Expanding '\n",
      "                         'internationally, pursuing large retail market '\n",
      "                         'segments that are still nascent for Amazon, and '\n",
      "                         'using our unique assets to help merchants sell more '\n",
      "                         'effectively on their own websites are somewhat '\n",
      "                         'natural extensions for us. There are also a few '\n",
      "                         'investments we’re making that are further from our '\n",
      "                         'core businesses, but where we see unique '\n",
      "                         'opportunity. In 2003, AWS would have been a classic '\n",
      "                         'example. In 2023, Amazon Healthcare and Kuiper are '\n",
      "                         'potential analogues.   Our initial efforts in '\n",
      "                         'Healthcare began with pharmacy, which felt less like '\n",
      "                         'a major departure from ecommerce. For years, Amazon '\n",
      "                         'customers had asked us when we’d offer them an '\n",
      "                         'online pharmacy as their frustrations mounted with '\n",
      "                         'current providers. Launched in 2020, Amazon Pharmacy '\n",
      "                         'is a full-service, online pharmacy that offers '\n",
      "                         'transparent pricing, easy refills, and savings for '\n",
      "                         'Prime members. The business is growing quickly, and '\n",
      "                         'continues to innovate. An example is Amazon '\n",
      "                         'Pharmacy’s recent launch of RxPass, which for a $5 '\n",
      "                         'per        month flat fee, enables Prime members to '\n",
      "                         'get as many of the eligible prescription medications '\n",
      "                         'as they need for dozens of common conditions, like '\n",
      "                         'high blood pressure, acid reflux, and anxiety.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-east-1-194722403835/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3A0c0eXZIBhGxTQSFs8-s4',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'D3K2AJRT1I',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-east-1-194722403835/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "    'score': 0.53212637},\n",
      "  { 'content': { 'text': 'Amazon provides every full-time employee with health '\n",
      "                         'insurance, a 401(k) plan, 20 weeks paid maternity '\n",
      "                         'leave, and other benefits. These are the same '\n",
      "                         'benefits that Amazon’s most senior executives '\n",
      "                         'receive. And with our rapidly changing economy, we '\n",
      "                         'see more clearly than ever the need for workers to '\n",
      "                         'evolve their skills continually to keep up with '\n",
      "                         'technology. That’s why we’re spending $700 million '\n",
      "                         'to provide more than 100,000 Amazonians access to '\n",
      "                         'training programs, at their places of work, in '\n",
      "                         'high-demand fields such as healthcare, cloud '\n",
      "                         'computing, and machine learning. Since 2012, we have '\n",
      "                         'offered Career Choice, a pre-paid tuition program '\n",
      "                         'for fulfillment center associates looking to move '\n",
      "                         'into high- demand occupations. Amazon pays up to 95% '\n",
      "                         'of tuition and fees toward a certificate or diploma '\n",
      "                         'in qualified fields of study, leading to enhanced '\n",
      "                         'employment opportunities in high-demand jobs. Since '\n",
      "                         'its launch, more than 25,000 Amazonians have '\n",
      "                         'received training for in-demand occupations.   To '\n",
      "                         'ensure that future generations have the skills they '\n",
      "                         'need to thrive in a technology-driven economy, we '\n",
      "                         'started a program last year called Amazon Future '\n",
      "                         'Engineer, which is designed to educate and train '\n",
      "                         'low-income and disadvantaged young people to pursue '\n",
      "                         'careers in computer science. We have an ambitious '\n",
      "                         'goal: to help hundreds of thousands of students each '\n",
      "                         'year learn computer science and coding. Amazon '\n",
      "                         'Future Engineer currently funds Introduction to '\n",
      "                         'Computer Science and AP Computer Science classes for '\n",
      "                         'more than 2,000 schools in underserved communities '\n",
      "                         'across the country. Each year, Amazon Future '\n",
      "                         'Engineer also gives 100 four-year, $40,000 college '\n",
      "                         'scholarships to computer science students from '\n",
      "                         'low-income backgrounds. Those scholarship recipients '\n",
      "                         'also receive guaranteed, paid internships at Amazon '\n",
      "                         'after their first year of college. Our program in '\n",
      "                         'the UK funds 120 engineering apprenticeships and '\n",
      "                         'helps students from disadvantaged backgrounds pursue '\n",
      "                         'technology careers.   For now, my own time and '\n",
      "                         'thinking continues to be focused on COVID-19 and how '\n",
      "                         'Amazon can help while we’re in the middle of it. I '\n",
      "                         'am extremely grateful to my fellow Amazonians for '\n",
      "                         'all the grit and ingenuity they are showing as we '\n",
      "                         'move through this. You can count on all of us to '\n",
      "                         'look beyond the immediate crisis for insights and '\n",
      "                         'lessons and how to apply them going forward.   '\n",
      "                         'Reflect on this from Theodor Seuss Geisel:   “When '\n",
      "                         'something bad happens you have three choices. You '\n",
      "                         'can either let it define you, let it destroy you, or '\n",
      "                         'you can let it strengthen you.”   I am very '\n",
      "                         'optimistic about which of these civilization is '\n",
      "                         'going to choose.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://bedrock-kb-us-east-1-194722403835/AMZN-2019-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'metadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3AzXUeXZIBX45Wg_3A93qF',\n",
      "                  'x-amz-bedrock-kb-data-source-id': 'D3K2AJRT1I',\n",
      "                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-us-east-1-194722403835/AMZN-2019-Shareholder-Letter.pdf'},\n",
      "    'score': 0.5115285}]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Amazon doing in the field of generative AI?\"\n",
    "response = retrieve(query, kb_id, 5)\n",
    "retrievalResults = response['retrievalResults']\n",
    "pp.pprint(retrievalResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "653fd2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch context from the response\n",
    "def get_contexts(retrievalResults):\n",
    "    contexts = []\n",
    "    for retrievedResult in retrievalResults: \n",
    "        contexts.append(retrievedResult['content']['text'])\n",
    "    return contexts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ba479f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 'Imagine what they’ll be able to do with reliable connectivity, from people '\n",
      "  'taking online education courses, using financial services, starting their '\n",
      "  'own businesses, doing their shopping, enjoying entertainment, to businesses '\n",
      "  'and governments improving their coverage, efficiency, and operations. '\n",
      "  'Kuiper will deliver not only accessibility, but affordability. Our teams '\n",
      "  'have developed low-cost antennas (i.e. customer terminals) that will lower '\n",
      "  'the barriers to access. We recently unveiled the new terminals that will '\n",
      "  'communicate with the satellites passing overhead, and we expect to be able '\n",
      "  'to produce our standard residential version for less than $400 each. '\n",
      "  'They’re small: 11 inches square, 1 inch thick, and weigh less than 5 pounds '\n",
      "  'without their mounting bracket, but they deliver speeds up to 400 megabits '\n",
      "  'per second. And they’re powered by Amazon-designed baseband chips. We’re '\n",
      "  'preparing to launch two prototype satellites to test the entire end-to-end '\n",
      "  'communications network this year, and plan to be in beta with commercial '\n",
      "  'customers in 2024. The customer reaction to what we’ve shared thus far '\n",
      "  'about Kuiper has been very positive, and we believe Kuiper represents a '\n",
      "  'very large potential opportunity for Amazon. It also shares several '\n",
      "  'similarities to AWS in that it’s capital intensive at the start, but has a '\n",
      "  'large prospective consumer, enterprise, and government customer base, '\n",
      "  'significant revenue and operating profit potential, and relatively few '\n",
      "  'companies with the technical and inventive aptitude, as well as the '\n",
      "  'investment hypothesis to go after it.   One final investment area that I’ll '\n",
      "  'mention, that’s core to setting Amazon up to invent in every area of our '\n",
      "  'business for many decades to come, and where we’re investing heavily is '\n",
      "  'Large Language Models (“LLMs”) and Generative AI. Machine learning has been '\n",
      "  'a technology with high promise for several decades, but it’s only been the '\n",
      "  'last five to ten years that it’s started to be used more pervasively by '\n",
      "  'companies. This shift was driven by several factors, including access to '\n",
      "  'higher volumes of compute capacity at lower prices than was ever available. '\n",
      "  'Amazon has been using machine learning extensively for 25 years, employing '\n",
      "  'it in everything from personalized ecommerce recommendations, to '\n",
      "  'fulfillment center pick paths, to drones for Prime Air, to Alexa, to the '\n",
      "  'many machine learning services AWS offers (where AWS has the broadest '\n",
      "  'machine learning functionality and customer base of any cloud provider). '\n",
      "  'More recently, a newer form of machine learning, called Generative AI, has '\n",
      "  'burst onto the scene and promises to significantly accelerate machine '\n",
      "  'learning adoption.',\n",
      "  'Amazon has been using machine learning extensively for 25 years, employing '\n",
      "  'it in everything from personalized ecommerce recommendations, to '\n",
      "  'fulfillment center pick paths, to drones for Prime Air, to Alexa, to the '\n",
      "  'many machine learning services AWS offers (where AWS has the broadest '\n",
      "  'machine learning functionality and customer base of any cloud provider). '\n",
      "  'More recently, a newer form of machine learning, called Generative AI, has '\n",
      "  'burst onto the scene and promises to significantly accelerate machine '\n",
      "  'learning adoption. Generative AI is based on very Large Language Models '\n",
      "  '(trained on up to hundreds of billions of parameters, and growing), across '\n",
      "  'expansive datasets, and has radically general and broad recall and learning '\n",
      "  'capabilities. We have been working on our own LLMs for a while now, believe '\n",
      "  'it will transform and improve virtually every customer experience, and will '\n",
      "  'continue to invest substantially in these models across all of our '\n",
      "  'consumer, seller, brand, and creator experiences. Additionally, as we’ve '\n",
      "  'done for years in AWS, we’re democratizing this technology so companies of '\n",
      "  'all sizes can leverage Generative AI. AWS is offering the most '\n",
      "  'price-performant machine learning chips in Trainium and Inferentia so small '\n",
      "  'and large companies can afford to train and run their LLMs in production. '\n",
      "  'We enable companies to choose from various LLMs and build applications with '\n",
      "  'all of the AWS security, privacy and other features that customers are '\n",
      "  'accustomed to using. And, we’re delivering applications like AWS’s '\n",
      "  'CodeWhisperer, which revolutionizes        developer productivity by '\n",
      "  'generating code suggestions in real time. I could write an entire letter on '\n",
      "  'LLMs and Generative AI as I think they will be that transformative, but '\n",
      "  'I’ll leave that for a future letter. Let’s just say that LLMs and '\n",
      "  'Generative AI are going to be a big deal for customers, our shareholders, '\n",
      "  'and Amazon.   So, in closing, I’m optimistic that we’ll emerge from this '\n",
      "  'challenging macroeconomic time in a stronger position than when we entered '\n",
      "  'it. There are several reasons for it and I’ve mentioned many of them above. '\n",
      "  'But, there are two relatively simple statistics that underline our immense '\n",
      "  'future opportunity. While we have a consumer business that’s $434B in 2022, '\n",
      "  'the vast majority of total market segment share in global retail still '\n",
      "  'resides in physical stores (roughly 80%). And, it’s a similar story for '\n",
      "  'Global IT spending, where we have AWS revenue of $80B in 2022, with about '\n",
      "  '90% of Global IT spending still on-premises and yet to migrate to the '\n",
      "  'cloud.',\n",
      "  'Our Inferentia2 chip, which just launched, offers up to four times higher '\n",
      "  'throughput and ten times lower latency than our first Inferentia processor. '\n",
      "  'With the enormous upcoming growth in machine learning, customers will be '\n",
      "  'able to get a lot more done with AWS’s training and inference chips at a '\n",
      "  'significantly lower cost. We’re not close to being done innovating here, '\n",
      "  'and this long-term investment should prove fruitful for both customers and '\n",
      "  'AWS. AWS is still in the early stages of its evolution, and has a chance '\n",
      "  'for unusual growth in the next decade.   Similarly high potential, Amazon’s '\n",
      "  'Advertising business is uniquely effective for brands, which is part of why '\n",
      "  'it continues to grow at a brisk clip. Akin to physical retailers’ '\n",
      "  'advertising businesses selling shelf space, end- caps, and placement in '\n",
      "  'their circulars, our sponsored products and brands offerings have been an '\n",
      "  'integral part        of the Amazon shopping experience for more than a '\n",
      "  'decade. However, unlike physical retailers, Amazon can tailor these '\n",
      "  'sponsored products to be relevant to what customers are searching for given '\n",
      "  'what we know about shopping behaviors and our very deep investment in '\n",
      "  'machine learning algorithms. This leads to advertising that’s more useful '\n",
      "  'for customers; and as a result, performs better for brands. This is part of '\n",
      "  'why our Advertising revenue has continued to grow rapidly (23% YoY in Q4 '\n",
      "  '2022, 25% YoY overall for 2022 on a $31B revenue base), even as most large '\n",
      "  'advertising-focused businesses’ growth have slowed over the last several '\n",
      "  'quarters.   We strive to be the best place for advertisers to build their '\n",
      "  'brands. We have near and long-term opportunities that will help us achieve '\n",
      "  'that mission. We’re continuing to make large investments in machine '\n",
      "  'learning to keep honing our advertising selection algorithms. For the past '\n",
      "  'couple of years, we’ve invested in building comprehensive, flexible, and '\n",
      "  'durable planning and measurement solutions, giving marketers greater '\n",
      "  'insight into advertising effectiveness. An example is Amazon Marketing '\n",
      "  'Cloud (“AMC”). AMC is a “clean room” (i.e. secure digital environment) in '\n",
      "  'which advertisers can run custom audience and campaign analytics across a '\n",
      "  'range of first and third-party inputs, in a privacy-safe manner, to '\n",
      "  'generate advertising and business insights to inform their broader '\n",
      "  'marketing and sales strategies. The Advertising and AWS teams have '\n",
      "  'collaborated to enable companies to store their data in AWS, operate '\n",
      "  'securely in AMC with Amazon and other third-party data sources, perform '\n",
      "  'analytics in AWS, and have the option to activate advertising on Amazon or '\n",
      "  'third-party publishers through the Amazon Demand-Side Platform.',\n",
      "  'We believe that we’ve only scratched the surface of what’s possible to '\n",
      "  'date, and plan to keep building the features our business customers tell us '\n",
      "  'they need and want.   While many brands and merchants successfully sell '\n",
      "  'their products on Amazon’s marketplace, there are also a large number of '\n",
      "  'brands and sellers who have launched their own direct-to-consumer websites. '\n",
      "  'One of the challenges for these merchants is driving conversion from views '\n",
      "  'to purchases. We invented Buy with Prime to help with this challenge. Buy '\n",
      "  'with Prime allows third-party brands and sellers to offer their products on '\n",
      "  'their own websites to our large Amazon Prime membership, and offer those '\n",
      "  'customers fast, free Prime shipping and seamless checkout with their Amazon '\n",
      "  'account. Buy with Prime provides merchants several additional benefits, '\n",
      "  'including Amazon handling the product storage, picking, packing, delivery, '\n",
      "  'payment, and any returns, all through Amazon Pay and Fulfillment by Amazon. '\n",
      "  'Buy with Prime has recently been made available to all US merchants; and so '\n",
      "  'far, Buy with Prime has increased shopper conversion on third-party '\n",
      "  'shopping sites by 25% on average. Merchants are excited about converting '\n",
      "  'more sales and fulfilling these shipments more easily, Prime members love '\n",
      "  'that they can use their Prime benefits on more destinations, and Buy with '\n",
      "  'Prime allows us to improve the shopping experience across more of the '\n",
      "  'web.   Expanding internationally, pursuing large retail market segments '\n",
      "  'that are still nascent for Amazon, and using our unique assets to help '\n",
      "  'merchants sell more effectively on their own websites are somewhat natural '\n",
      "  'extensions for us. There are also a few investments we’re making that are '\n",
      "  'further from our core businesses, but where we see unique opportunity. In '\n",
      "  '2003, AWS would have been a classic example. In 2023, Amazon Healthcare and '\n",
      "  'Kuiper are potential analogues.   Our initial efforts in Healthcare began '\n",
      "  'with pharmacy, which felt less like a major departure from ecommerce. For '\n",
      "  'years, Amazon customers had asked us when we’d offer them an online '\n",
      "  'pharmacy as their frustrations mounted with current providers. Launched in '\n",
      "  '2020, Amazon Pharmacy is a full-service, online pharmacy that offers '\n",
      "  'transparent pricing, easy refills, and savings for Prime members. The '\n",
      "  'business is growing quickly, and continues to innovate. An example is '\n",
      "  'Amazon Pharmacy’s recent launch of RxPass, which for a $5 per        month '\n",
      "  'flat fee, enables Prime members to get as many of the eligible prescription '\n",
      "  'medications as they need for dozens of common conditions, like high blood '\n",
      "  'pressure, acid reflux, and anxiety.',\n",
      "  'Amazon provides every full-time employee with health insurance, a 401(k) '\n",
      "  'plan, 20 weeks paid maternity leave, and other benefits. These are the same '\n",
      "  'benefits that Amazon’s most senior executives receive. And with our rapidly '\n",
      "  'changing economy, we see more clearly than ever the need for workers to '\n",
      "  'evolve their skills continually to keep up with technology. That’s why '\n",
      "  'we’re spending $700 million to provide more than 100,000 Amazonians access '\n",
      "  'to training programs, at their places of work, in high-demand fields such '\n",
      "  'as healthcare, cloud computing, and machine learning. Since 2012, we have '\n",
      "  'offered Career Choice, a pre-paid tuition program for fulfillment center '\n",
      "  'associates looking to move into high- demand occupations. Amazon pays up to '\n",
      "  '95% of tuition and fees toward a certificate or diploma in qualified fields '\n",
      "  'of study, leading to enhanced employment opportunities in high-demand jobs. '\n",
      "  'Since its launch, more than 25,000 Amazonians have received training for '\n",
      "  'in-demand occupations.   To ensure that future generations have the skills '\n",
      "  'they need to thrive in a technology-driven economy, we started a program '\n",
      "  'last year called Amazon Future Engineer, which is designed to educate and '\n",
      "  'train low-income and disadvantaged young people to pursue careers in '\n",
      "  'computer science. We have an ambitious goal: to help hundreds of thousands '\n",
      "  'of students each year learn computer science and coding. Amazon Future '\n",
      "  'Engineer currently funds Introduction to Computer Science and AP Computer '\n",
      "  'Science classes for more than 2,000 schools in underserved communities '\n",
      "  'across the country. Each year, Amazon Future Engineer also gives 100 '\n",
      "  'four-year, $40,000 college scholarships to computer science students from '\n",
      "  'low-income backgrounds. Those scholarship recipients also receive '\n",
      "  'guaranteed, paid internships at Amazon after their first year of college. '\n",
      "  'Our program in the UK funds 120 engineering apprenticeships and helps '\n",
      "  'students from disadvantaged backgrounds pursue technology careers.   For '\n",
      "  'now, my own time and thinking continues to be focused on COVID-19 and how '\n",
      "  'Amazon can help while we’re in the middle of it. I am extremely grateful to '\n",
      "  'my fellow Amazonians for all the grit and ingenuity they are showing as we '\n",
      "  'move through this. You can count on all of us to look beyond the immediate '\n",
      "  'crisis for insights and lessons and how to apply them going forward.   '\n",
      "  'Reflect on this from Theodor Seuss Geisel:   “When something bad happens '\n",
      "  'you have three choices. You can either let it define you, let it destroy '\n",
      "  'you, or you can let it strengthen you.”   I am very optimistic about which '\n",
      "  'of these civilization is going to choose.']\n"
     ]
    }
   ],
   "source": [
    "contexts = get_contexts(retrievalResults)\n",
    "pp.pprint(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec855b4",
   "metadata": {},
   "source": [
    "# Prompt specific to the model to personalize responses\n",
    "\n",
    "Here, we will use the specific prompt below for the model to act as a financial advisor AI system that will provide answers to questions by using fact based and statistical information when possible. We will provide the Retrieve API responses from above as a part of the {contexts} in the prompt for the model to refer to, along with the user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99093ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Human: You are a financial advisor AI system, and provides answers to questions by using fact based and statistical information when possible. \n",
    "Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "<context>\n",
    "{contexts}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{query}\n",
    "</question>\n",
    "\n",
    "The response should be specific and use statistics or numbers when possible.\n",
    "\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf9231a",
   "metadata": {},
   "source": [
    "# LangChain integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d73ee11a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_aws'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20564/368183202.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain_aws\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mChatBedrock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrievers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbedrock\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAmazonKnowledgeBasesRetriever\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m llm = ChatBedrock(model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n\u001b[0;32m      5\u001b[0m               client = bedrock_client)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_aws'"
     ]
    }
   ],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n",
    "\n",
    "llm = ChatBedrock(model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "              client = bedrock_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "900eef77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b48400d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1058a3c2",
   "metadata": {},
   "source": [
    "# Sab Delete "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3b5f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98f4b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3_session = boto3.Session()\n",
    "bedrock_agent_client = boto3_session.client('bedrock-agent', region_name=boto3_session.region_name)\n",
    "aoss_client = boto3.client('opensearchserverless')\n",
    "s3_client = boto3_session.client('s3', region_name=boto3_session.region_name)\n",
    "iam_client = boto3.client(\"iam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ffd7dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_agent_client.list_data_sources(\n",
    "    knowledgeBaseId=kb_id,\n",
    ")\n",
    "data_source_ids = [ x['dataSourceId'] for x in response['dataSourceSummaries']]\n",
    "\n",
    "for data_source_id in data_source_ids:\n",
    "    bedrock_agent_client.delete_data_source(dataSourceId = data_source_id, knowledgeBaseId=kb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "803ed954",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_agent_client.list_data_sources(\n",
    "    knowledgeBaseId=kb_id,\n",
    ")\n",
    "data_source_ids = [ x['dataSourceId'] for x in response['dataSourceSummaries']]\n",
    "\n",
    "for data_source_id in data_source_ids:\n",
    "    bedrock_agent_client.delete_data_source(dataSourceId = data_source_id, knowledgeBaseId=kb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f38cfa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_agent_client.get_knowledge_base(knowledgeBaseId=kb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2276573",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_role_name = response['knowledgeBase']['roleArn'].split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4dc1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_attached_role_policies_response = iam_client.list_attached_role_policies(\n",
    "    RoleName=kb_role_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3fbba383",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_attached_role_policies = kb_attached_role_policies_response['AttachedPolicies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90b6e691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'd0961c5b-a374-4e03-937f-b7cc5979c54c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'd0961c5b-a374-4e03-937f-b7cc5979c54c',\n",
       "   'date': 'Tue, 08 Oct 2024 22:08:28 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock_agent_client.delete_knowledge_base(knowledgeBaseId=kb_id)\n",
    "aoss_client.delete_collection(id=collection['createCollectionDetail']['id'])\n",
    "aoss_client.delete_access_policy(type=\"data\", name=access_policy['accessPolicyDetail']['name'])\n",
    "aoss_client.delete_security_policy(type=\"network\", name=network_policy['securityPolicyDetail']['name'])\n",
    "aoss_client.delete_security_policy(type=\"encryption\", name=encryption_policy['securityPolicyDetail']['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "663417db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for policy in kb_attached_role_policies:\n",
    "    iam_client.detach_role_policy(\n",
    "            RoleName=kb_role_name,\n",
    "            PolicyArn=policy['PolicyArn']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c975d47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '9031c14c-211f-4667-8089-8e501552ec04',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Tue, 08 Oct 2024 22:08:31 GMT',\n",
       "   'x-amzn-requestid': '9031c14c-211f-4667-8089-8e501552ec04',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '200'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iam_client.delete_role(RoleName=kb_role_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "432da392",
   "metadata": {},
   "outputs": [],
   "source": [
    "for policy in kb_attached_role_policies:\n",
    "    iam_client.delete_policy(PolicyArn=policy['PolicyArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9a02e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'ZR0F7F3MBRMZPABR',\n",
       "  'HostId': '4M5hvzJI0AvmMASPYSXbqdS86bOk80BPHm5LM7ieIsGmaUg+9PDkQopKB9ZJ3t/8PGaaVTmoROM=',\n",
       "  'HTTPStatusCode': 204,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '4M5hvzJI0AvmMASPYSXbqdS86bOk80BPHm5LM7ieIsGmaUg+9PDkQopKB9ZJ3t/8PGaaVTmoROM=',\n",
       "   'x-amz-request-id': 'ZR0F7F3MBRMZPABR',\n",
       "   'date': 'Tue, 08 Oct 2024 22:08:35 GMT',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects = s3_client.list_objects(Bucket=bucket_name)\n",
    "if 'Contents' in objects:\n",
    "    for obj in objects['Contents']:\n",
    "        s3_client.delete_object(Bucket=bucket_name, Key=obj['Key'])\n",
    "s3_client.delete_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d54e762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
